{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flair.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keenandrea/Flair/blob/master/Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sADzWfqEwf1f",
        "colab_type": "text"
      },
      "source": [
        "# Flair: A Natural Language Processing Library\n",
        "\n",
        "---\n",
        "\n",
        "Flair is an NLP library whose framework builds on top of *PyTorch*. Several NLP tasks Flair can handle include *Name-Entity Recognition*, *Parts-of-Speech Tagging*, *Text Classification*, and *Custom Language Modeling*.\n",
        "\n",
        "What makes Flair admirable is how it comprises itself from SOA word embeddings, allowing users to combine different embeddings to documents.\n",
        "\n",
        "---\n",
        "\n",
        "## contextual string embeddings for sequence labeling\n",
        "\n",
        "---\n",
        "\n",
        "Contextual String Embeddings leverage the internal states of a trained character language model to produce a novel type of word embedding. It uses certain internal principles of a trained character language model, such that words can have different meaning in different sentences.\n",
        "\n",
        "The words are trained as characters in contenxtual string embeddings, and the embeddings are contextualized by their surrounding text. What this means is the same words can have different embeddings depending on the context.\n",
        "\n",
        "Take, for instance, the word *key*. In some ways it is an object which unlocks, in others it is the fulcrum of rhetoric as in the *key* takeaway or the *key* point, and still, in others, it is the labeling of a value as in *key*-value pairs.\n",
        "\n",
        "With contextual string embedding, each of these *keys* are given seperate context. Think of all the cases in which the same word in the English language is under different context domains and you'll see the boon of the tool.\n",
        "\n",
        "---\n",
        "\n",
        "## performing with Flair\n",
        "\n",
        "---\n",
        "We're going to exemplify the performance of Flair using the *Twitter Sentiment Analysis* dataset, downloaded from [Kaggle](https://www.kaggle.com/paoloripamonti/twitter-sentiment-analysis). \n",
        "\n",
        "Follow the link provided, download the *.csv*, upload the *.csv* into a colab notebook instance; set runtime to *Python 3* and *GPU*, and you're set to go.\n",
        "\n",
        "---\n",
        "\n",
        "## connecting to *Google Drive*, importing dataset\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guNydQUjrEII",
        "colab_type": "code",
        "outputId": "45d8c257-81fa-4869-e67e-fa372d612a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "# file_id = '1fr4ff3mLKTY0WOvXI1x4Fj9Xu_hgxyQV' ### File ID ###\n",
        "file_id = '1GhyH4k9C4uPRnMAMKhJYOqa-V9Tqt4q8' ### File ID ###\n",
        "data = drive.CreateFile({'id': file_id})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y849yL80zqy7",
        "colab_type": "text"
      },
      "source": [
        "## transferring dataset into readable format\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPrDLWiWgjRC",
        "colab_type": "code",
        "outputId": "548eecbb-8302-4b30-993a-1f1718d48d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(io.StringIO(data.GetContentString())) \n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user  user thanks for  lyft credit i can t us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide  society now     motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  label                                              tweet\n",
              "0           0    0.0    user when a father is dysfunctional and is s...\n",
              "1           1    0.0   user  user thanks for  lyft credit i can t us...\n",
              "2           2    0.0                                bihday your majesty\n",
              "3           3    0.0   model   i love u take with u all the time in ...\n",
              "4           4    0.0             factsguide  society now     motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioV4FmP4gxpE",
        "colab_type": "code",
        "outputId": "50838fbf-ea06-4cdc-ff2e-330deff63256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        }
      },
      "source": [
        "# download Flair \n",
        "# on top PyTorch\n",
        "import torch\n",
        "!pip install flair\n",
        "import flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Collecting pytorch-pretrained-bert>=0.6.1 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Collecting regex (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n",
            "Collecting bpemb>=0.2.9 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting mpld3==0.3 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.2)\n",
            "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.162)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.0.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
            "Collecting sentencepiece (from bpemb>=0.2.9->flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.13.2)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.162 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.162)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.3.9)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.162->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
            "Building wheels for collected packages: sqlitedict, segtok, regex, mpld3\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "Successfully built sqlitedict segtok regex mpld3\n",
            "Installing collected packages: sqlitedict, deprecated, regex, segtok, pytorch-pretrained-bert, sentencepiece, bpemb, mpld3, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.5 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.6.8 segtok-1.5.7 sentencepiece-0.1.82 sqlitedict-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS8MOt_DhPdJ",
        "colab_type": "text"
      },
      "source": [
        "Flair data types have two objects, namely *sentence* and *token* objects, which are cardinal appendeges of the library. Sentences are lists of tokens that hold textual sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2BZUMgKhAZo",
        "colab_type": "code",
        "outputId": "35df7b5f-cee9-40d1-98cc-7ad459af3b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "s = Sentence('To be or not too.')\n",
        "print(Sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'flair.data.Sentence'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp6kNta83dY-",
        "colab_type": "code",
        "outputId": "e8b7defc-148f-48ff-9ed8-31900d0b8007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "s = Sentence('To be or not too.')\n",
        "# see what's inside the sentence\n",
        "print(s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"To be or not too.\" - 5 Tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zaj4uZejmG6",
        "colab_type": "code",
        "outputId": "0830dcd4-2656-43e3-e07b-e176fb52a91c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#extracting the tweet part#\n",
        "text = data['tweet'] \n",
        " ## txt is a list of tweets ##\n",
        "txt = text.tolist()\n",
        "print(txt[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['  user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction     run', ' user  user thanks for  lyft credit i can t use cause they don t offer wheelchair vans in pdx      disapointed  getthanked', '  bihday your majesty', ' model   i love u take with u all the time in ur                                      ', ' factsguide  society now     motivation', '      huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo  ', '  user camping tomorrow  user  user  user  user  user  user  user danny   ', 'the next school year is the year for exams      can t think about that       school  exams    hate  imagine  actorslife  revolutionschool  girl', 'we won    love the land     allin  cavs  champions  cleveland  clevelandcavaliers      ', '  user  user welcome here    i m   it s so  gr    ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVMWZvnD0K0p",
        "colab_type": "text"
      },
      "source": [
        "## word embeddings with *Flair*\n",
        "\n",
        "---\n",
        "\n",
        "A few of the more popular word embeddings are written into the cell below. We will be using Stacked Embeddings to combine multiple embeddings to build a word representation model with great power and little complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA2kOtoC0DHC",
        "colab_type": "code",
        "outputId": "743690d7-b097-4a38-a969-5d4bf8160672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.embeddings import CharacterEmbeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "from flair.embeddings import BertEmbeddings\n",
        "from flair.embeddings import ELMoEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "### Initialising embeddings (un-comment to use others) ###\n",
        "#glove_embedding = WordEmbeddings('glove')\n",
        "#character_embeddings = CharacterEmbeddings()\n",
        "flair_forward  = FlairEmbeddings('news-forward-fast')\n",
        "flair_backward = FlairEmbeddings('news-backward-fast')\n",
        "#bert_embedding = BertEmbedding()\n",
        "#elmo_embedding = ElmoEmbedding()\n",
        "\n",
        "stacked_embeddings = StackedEmbeddings(embeddings = [ \n",
        "                                                      flair_forward, \n",
        "                                                      flair_backward\n",
        "                                                    ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-13 15:52:03,285 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmphal31cc6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:01<00:00, 11157452.41B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-13 15:52:05,602 copying /tmp/tmphal31cc6 to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2019-06-13 15:52:05,623 removing temp file /tmp/tmphal31cc6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-13 15:52:13,012 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpkq2ebney\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:01<00:00, 11485513.42B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-13 15:52:15,263 copying /tmp/tmpkq2ebney to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2019-06-13 15:52:15,286 removing temp file /tmp/tmpkq2ebney\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ZlKZM264au",
        "colab_type": "text"
      },
      "source": [
        "Here we can mix and match flair.embedding library imports and test the make and model of our stacked embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S6AMvkm2Saz",
        "colab_type": "code",
        "outputId": "4b343ab9-a949-48dd-bc97-2c573610ba12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# create a sentence\n",
        "s = Sentence('To be or not too.')\n",
        "# embed words in sentence\n",
        "stacked_embeddings.embed(s)\n",
        "for token in s:\n",
        "  print(token.embedding)\n",
        "# data type and size of embedding\n",
        "print(type(token.embedding))\n",
        "# storing size (length)\n",
        "z = token.embedding.size()[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.5548e-03, -1.5109e-06,  2.8850e-07,  ..., -2.4275e-08,\n",
            "         5.6365e-06,  1.2835e-02])\n",
            "tensor([ 1.5566e-03,  3.3451e-05,  1.0460e-06,  ..., -5.7873e-08,\n",
            "         2.3331e-03,  1.8155e-02])\n",
            "tensor([ 5.9643e-04, -1.0582e-06,  9.8358e-07,  ..., -4.2780e-08,\n",
            "        -2.3259e-03,  1.5929e-02])\n",
            "tensor([-1.0171e-02, -2.1711e-05,  6.7540e-06,  ..., -1.3955e-07,\n",
            "        -4.0077e-05,  1.1862e-03])\n",
            "tensor([-2.3813e-03, -3.6439e-06,  5.0253e-09,  ..., -1.7233e-09,\n",
            "        -3.2845e-04,  1.7303e-03])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN2Y7GdW7L2n",
        "colab_type": "text"
      },
      "source": [
        "## vectorizing the text\n",
        "\n",
        "---\n",
        "\n",
        "Here we can choose one of two approaches:\n",
        "\n",
        "    1) we calculate the mean of word embeddings\n",
        "    2) we vectorize the entire tweet\n",
        "Both of these approaches are listed below, respectively.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## calculating the mean of word embeddings\n",
        "\n",
        "---\n",
        "\n",
        "Our calculation approach for embeddings within a Tweet will take the following steps: \n",
        "\n",
        "    1) we generate a word embedding for each word \n",
        "    2) we calculate the mean of these embeddings to obtain the embedding of the sentence\n",
        "\n",
        "The running of this next cell takes some long time to complete. Fair warning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQKgDyob8hiz",
        "colab_type": "code",
        "outputId": "f7db5400-6260-436f-ee89-a2f03aa6a933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import to track pro\n",
        "# gress of our loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "# creating a tensor \n",
        "# to store sentence \n",
        "# embeddings \n",
        "s = torch.zeros(0,z)\n",
        "\n",
        "# iterating Sentence\n",
        "for tweet in tqdm(txt):   \n",
        "  # empty tensor for words \n",
        "  w = torch.zeros(0,z)   \n",
        "  sentence = Sentence(tweet)\n",
        "  stacked_embeddings.embed(sentence)\n",
        "  # loop for every word\n",
        "  for token in sentence:\n",
        "    # storing Embeddings of each word in a sentence\n",
        "    w = torch.cat((w,token.embedding.view(-1,z)),0)\n",
        "  # storing sentence Embeddings (obtains mean of all words)\n",
        "  s = torch.cat((s, w.mean(dim = 0).view(-1, z)),0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 49159/49159 [1:05:36<00:00,  6.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DglbprTZNmjo",
        "colab_type": "text"
      },
      "source": [
        "## document embedding\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "So you've chosen to perform some document embedding. In other words, we're going to vectorize the entire Tweet. This, too, is going to take some time. Grab your reading material."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYWwyCPShdxf",
        "colab_type": "code",
        "outputId": "94b5e8d3-31e0-4f72-e212-aaacd0222d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.embeddings import DocumentPoolEmbeddings\n",
        "\n",
        "### initialize the document embeddings, mode = mean ###\n",
        "document_embeddings = DocumentPoolEmbeddings([\n",
        "                                              flair_backward,\n",
        "                                              flair_forward\n",
        "                                             ])\n",
        "# # Storing Size of embedding\n",
        "z = sentence.embedding.size()[0]\n",
        "\n",
        "### Vectorising text ###\n",
        "# creating a tensor for storing sentence embeddings\n",
        "s = torch.zeros(0,z)\n",
        "# iterating Sentences #\n",
        "for tweet in tqdm(txt):   \n",
        "  sentence = Sentence(tweet)\n",
        "  document_embeddings.embed(sentence)\n",
        "  # Adding Document embeddings to list #\n",
        "  s = torch.cat((s, sentence.embedding.view(-1,z)),0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 49159/49159 [1:32:11<00:00,  5.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7ARXAztO3mX",
        "colab_type": "text"
      },
      "source": [
        "## partitioning the data between train and test sets\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXVlFz7Yn7iJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## tensor to numpy array ##\n",
        "X = s.detach().numpy()   \n",
        "\n",
        "## Test set ##\n",
        "test = X[31962:,:]\n",
        "train = X[:31962,:]\n",
        "\n",
        "# extracting labels of the training set #\n",
        "target = data['label'][data['label'].isnull()==False].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNrGFFpgMj1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6XY4_B3PG8B",
        "colab_type": "text"
      },
      "source": [
        "Up next, we're going to define a custom *F1 evaluator* for our upcoming *XGBoost* model.\n",
        "\n",
        "---\n",
        "\n",
        "## what the heek is an *f1 score*?\n",
        "\n",
        "---\n",
        "According to *Wikipedia*: in statistical analysis of binary classification, the f1 score is a measure of a test's accuracy. What it does, it considers both the *precision* (p) and the *recall* (r) of the test to compute the score. \n",
        "\n",
        "*p* is the number of correct positive results divided by the number of all positive results returned by the classifier.\n",
        "\n",
        "*r* is the number of correct positive results divided by the number of all relevent samples, or, all samples that should have been identified as positive.\n",
        "\n",
        "The f1 score is the harmonic average of the precision and recall. It's best values are those near 1, and its worst values are those near 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIx5Rq5n9Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_eval(preds, dtrain):\n",
        "    labels = dtrain.get_label().astype(np.int)\n",
        "    preds = (preds >= 0.3).astype(np.int)\n",
        "    return [('f1_score', f1_score(labels, preds))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvaEBLI4O_2r",
        "colab_type": "text"
      },
      "source": [
        "## building the model using *XGBoost*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5LyJMdiLYHN",
        "colab_type": "code",
        "outputId": "9150f818-eb5c-4ca1-d1e3-5a671daf1ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2383
        }
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "### Splitting training set ###\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train, target,  \n",
        "                                                      random_state=42, \n",
        "                                                          test_size=0.3)\n",
        "\n",
        "### XGBoost compatible data ###\n",
        "dtrain = xgb.DMatrix(x_train,y_train)         \n",
        "dvalid = xgb.DMatrix(x_valid, label = y_valid)\n",
        "\n",
        "### defining parameters ###\n",
        "params = {\n",
        "          'colsample': 0.9,\n",
        "          'colsample_bytree': 0.5,\n",
        "          'eta': 0.1,\n",
        "          'max_depth': 8,\n",
        "          'min_child_weight': 6,\n",
        "          'objective': 'binary:logistic',\n",
        "          'subsample': 0.9\n",
        "          }\n",
        "\n",
        "### Training the model ###\n",
        "xgb_model = xgb.train(\n",
        "                      params,\n",
        "                      dtrain,\n",
        "                      feval= custom_eval,\n",
        "                      num_boost_round= 1000,\n",
        "                      maximize=True,\n",
        "                      evals=[(dvalid, \"Validation\")],\n",
        "                      early_stopping_rounds=30\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tValidation-error:0.07373\tValidation-f1_score:0.133165\n",
            "Multiple eval metrics have been passed: 'Validation-f1_score' will be used for early stopping.\n",
            "\n",
            "Will train until Validation-f1_score hasn't improved in 30 rounds.\n",
            "[1]\tValidation-error:0.065075\tValidation-f1_score:0.133165\n",
            "[2]\tValidation-error:0.063927\tValidation-f1_score:0.133165\n",
            "[3]\tValidation-error:0.062363\tValidation-f1_score:0.133165\n",
            "[4]\tValidation-error:0.063719\tValidation-f1_score:0.133165\n",
            "[5]\tValidation-error:0.06278\tValidation-f1_score:0.297885\n",
            "[6]\tValidation-error:0.063197\tValidation-f1_score:0.376812\n",
            "[7]\tValidation-error:0.062467\tValidation-f1_score:0.41914\n",
            "[8]\tValidation-error:0.062676\tValidation-f1_score:0.42386\n",
            "[9]\tValidation-error:0.062885\tValidation-f1_score:0.436113\n",
            "[10]\tValidation-error:0.062572\tValidation-f1_score:0.444444\n",
            "[11]\tValidation-error:0.062572\tValidation-f1_score:0.427835\n",
            "[12]\tValidation-error:0.06278\tValidation-f1_score:0.43455\n",
            "[13]\tValidation-error:0.06278\tValidation-f1_score:0.438532\n",
            "[14]\tValidation-error:0.062467\tValidation-f1_score:0.437792\n",
            "[15]\tValidation-error:0.06278\tValidation-f1_score:0.438149\n",
            "[16]\tValidation-error:0.062363\tValidation-f1_score:0.429672\n",
            "[17]\tValidation-error:0.062259\tValidation-f1_score:0.432327\n",
            "[18]\tValidation-error:0.062467\tValidation-f1_score:0.424303\n",
            "[19]\tValidation-error:0.062155\tValidation-f1_score:0.413655\n",
            "[20]\tValidation-error:0.06205\tValidation-f1_score:0.418838\n",
            "[21]\tValidation-error:0.061842\tValidation-f1_score:0.422846\n",
            "[22]\tValidation-error:0.061842\tValidation-f1_score:0.424547\n",
            "[23]\tValidation-error:0.061633\tValidation-f1_score:0.430862\n",
            "[24]\tValidation-error:0.061216\tValidation-f1_score:0.429003\n",
            "[25]\tValidation-error:0.061216\tValidation-f1_score:0.430303\n",
            "[26]\tValidation-error:0.061007\tValidation-f1_score:0.433468\n",
            "[27]\tValidation-error:0.061216\tValidation-f1_score:0.435923\n",
            "[28]\tValidation-error:0.060799\tValidation-f1_score:0.43002\n",
            "[29]\tValidation-error:0.060799\tValidation-f1_score:0.435845\n",
            "[30]\tValidation-error:0.060277\tValidation-f1_score:0.438827\n",
            "[31]\tValidation-error:0.060173\tValidation-f1_score:0.430173\n",
            "[32]\tValidation-error:0.059965\tValidation-f1_score:0.440609\n",
            "[33]\tValidation-error:0.059547\tValidation-f1_score:0.442424\n",
            "[34]\tValidation-error:0.05986\tValidation-f1_score:0.441088\n",
            "[35]\tValidation-error:0.059547\tValidation-f1_score:0.440609\n",
            "[36]\tValidation-error:0.059756\tValidation-f1_score:0.448241\n",
            "[37]\tValidation-error:0.059443\tValidation-f1_score:0.456\n",
            "[38]\tValidation-error:0.05913\tValidation-f1_score:0.453094\n",
            "[39]\tValidation-error:0.05913\tValidation-f1_score:0.45\n",
            "[40]\tValidation-error:0.05913\tValidation-f1_score:0.45954\n",
            "[41]\tValidation-error:0.059026\tValidation-f1_score:0.461233\n",
            "[42]\tValidation-error:0.059235\tValidation-f1_score:0.45045\n",
            "[43]\tValidation-error:0.059235\tValidation-f1_score:0.456456\n",
            "[44]\tValidation-error:0.05913\tValidation-f1_score:0.460922\n",
            "[45]\tValidation-error:0.058817\tValidation-f1_score:0.453629\n",
            "[46]\tValidation-error:0.058817\tValidation-f1_score:0.453172\n",
            "[47]\tValidation-error:0.058817\tValidation-f1_score:0.461538\n",
            "[48]\tValidation-error:0.058817\tValidation-f1_score:0.460302\n",
            "[49]\tValidation-error:0.058609\tValidation-f1_score:0.458\n",
            "[50]\tValidation-error:0.058296\tValidation-f1_score:0.459839\n",
            "[51]\tValidation-error:0.058192\tValidation-f1_score:0.459082\n",
            "[52]\tValidation-error:0.058296\tValidation-f1_score:0.462761\n",
            "[53]\tValidation-error:0.057879\tValidation-f1_score:0.460775\n",
            "[54]\tValidation-error:0.057566\tValidation-f1_score:0.466733\n",
            "[55]\tValidation-error:0.057775\tValidation-f1_score:0.469307\n",
            "[56]\tValidation-error:0.05767\tValidation-f1_score:0.460922\n",
            "[57]\tValidation-error:0.057775\tValidation-f1_score:0.464322\n",
            "[58]\tValidation-error:0.057566\tValidation-f1_score:0.466\n",
            "[59]\tValidation-error:0.057566\tValidation-f1_score:0.466\n",
            "[60]\tValidation-error:0.057357\tValidation-f1_score:0.471173\n",
            "[61]\tValidation-error:0.057149\tValidation-f1_score:0.471754\n",
            "[62]\tValidation-error:0.057253\tValidation-f1_score:0.471173\n",
            "[63]\tValidation-error:0.057045\tValidation-f1_score:0.470356\n",
            "[64]\tValidation-error:0.056732\tValidation-f1_score:0.47619\n",
            "[65]\tValidation-error:0.056315\tValidation-f1_score:0.477318\n",
            "[66]\tValidation-error:0.056106\tValidation-f1_score:0.470356\n",
            "[67]\tValidation-error:0.056523\tValidation-f1_score:0.468254\n",
            "[68]\tValidation-error:0.056523\tValidation-f1_score:0.472799\n",
            "[69]\tValidation-error:0.056627\tValidation-f1_score:0.475345\n",
            "[70]\tValidation-error:0.056627\tValidation-f1_score:0.474877\n",
            "[71]\tValidation-error:0.056627\tValidation-f1_score:0.4714\n",
            "[72]\tValidation-error:0.056523\tValidation-f1_score:0.47591\n",
            "[73]\tValidation-error:0.056523\tValidation-f1_score:0.480864\n",
            "[74]\tValidation-error:0.056106\tValidation-f1_score:0.477318\n",
            "[75]\tValidation-error:0.056106\tValidation-f1_score:0.483301\n",
            "[76]\tValidation-error:0.055793\tValidation-f1_score:0.478346\n",
            "[77]\tValidation-error:0.055897\tValidation-f1_score:0.476378\n",
            "[78]\tValidation-error:0.05548\tValidation-f1_score:0.47929\n",
            "[79]\tValidation-error:0.055897\tValidation-f1_score:0.482283\n",
            "[80]\tValidation-error:0.055585\tValidation-f1_score:0.487709\n",
            "[81]\tValidation-error:0.055376\tValidation-f1_score:0.479763\n",
            "[82]\tValidation-error:0.055272\tValidation-f1_score:0.479763\n",
            "[83]\tValidation-error:0.055585\tValidation-f1_score:0.481737\n",
            "[84]\tValidation-error:0.055585\tValidation-f1_score:0.481188\n",
            "[85]\tValidation-error:0.055689\tValidation-f1_score:0.480237\n",
            "[86]\tValidation-error:0.055793\tValidation-f1_score:0.483712\n",
            "[87]\tValidation-error:0.055793\tValidation-f1_score:0.48419\n",
            "[88]\tValidation-error:0.055793\tValidation-f1_score:0.480237\n",
            "[89]\tValidation-error:0.055897\tValidation-f1_score:0.48269\n",
            "[90]\tValidation-error:0.056002\tValidation-f1_score:0.482143\n",
            "[91]\tValidation-error:0.055585\tValidation-f1_score:0.486166\n",
            "[92]\tValidation-error:0.05548\tValidation-f1_score:0.484669\n",
            "[93]\tValidation-error:0.055585\tValidation-f1_score:0.488142\n",
            "[94]\tValidation-error:0.055585\tValidation-f1_score:0.493583\n",
            "[95]\tValidation-error:0.055585\tValidation-f1_score:0.492095\n",
            "[96]\tValidation-error:0.05548\tValidation-f1_score:0.487129\n",
            "[97]\tValidation-error:0.05548\tValidation-f1_score:0.491089\n",
            "[98]\tValidation-error:0.055376\tValidation-f1_score:0.493609\n",
            "[99]\tValidation-error:0.055376\tValidation-f1_score:0.491609\n",
            "[100]\tValidation-error:0.055167\tValidation-f1_score:0.493069\n",
            "[101]\tValidation-error:0.055272\tValidation-f1_score:0.494094\n",
            "[102]\tValidation-error:0.054959\tValidation-f1_score:0.492611\n",
            "[103]\tValidation-error:0.054959\tValidation-f1_score:0.491159\n",
            "[104]\tValidation-error:0.054855\tValidation-f1_score:0.487179\n",
            "[105]\tValidation-error:0.054542\tValidation-f1_score:0.48766\n",
            "[106]\tValidation-error:0.054855\tValidation-f1_score:0.485149\n",
            "[107]\tValidation-error:0.054542\tValidation-f1_score:0.484127\n",
            "[108]\tValidation-error:0.05475\tValidation-f1_score:0.489635\n",
            "[109]\tValidation-error:0.054646\tValidation-f1_score:0.493583\n",
            "[110]\tValidation-error:0.055063\tValidation-f1_score:0.489594\n",
            "[111]\tValidation-error:0.055272\tValidation-f1_score:0.488095\n",
            "[112]\tValidation-error:0.055167\tValidation-f1_score:0.486111\n",
            "[113]\tValidation-error:0.054959\tValidation-f1_score:0.484\n",
            "[114]\tValidation-error:0.054959\tValidation-f1_score:0.488048\n",
            "[115]\tValidation-error:0.054959\tValidation-f1_score:0.481518\n",
            "[116]\tValidation-error:0.054959\tValidation-f1_score:0.48858\n",
            "[117]\tValidation-error:0.055063\tValidation-f1_score:0.487562\n",
            "[118]\tValidation-error:0.055376\tValidation-f1_score:0.488534\n",
            "[119]\tValidation-error:0.055376\tValidation-f1_score:0.486\n",
            "[120]\tValidation-error:0.055063\tValidation-f1_score:0.486486\n",
            "[121]\tValidation-error:0.055376\tValidation-f1_score:0.489468\n",
            "[122]\tValidation-error:0.055376\tValidation-f1_score:0.490982\n",
            "[123]\tValidation-error:0.055063\tValidation-f1_score:0.492492\n",
            "[124]\tValidation-error:0.054959\tValidation-f1_score:0.489468\n",
            "[125]\tValidation-error:0.05475\tValidation-f1_score:0.490982\n",
            "[126]\tValidation-error:0.055272\tValidation-f1_score:0.485944\n",
            "[127]\tValidation-error:0.055167\tValidation-f1_score:0.488978\n",
            "[128]\tValidation-error:0.054855\tValidation-f1_score:0.488488\n",
            "[129]\tValidation-error:0.054959\tValidation-f1_score:0.487462\n",
            "[130]\tValidation-error:0.054855\tValidation-f1_score:0.483936\n",
            "[131]\tValidation-error:0.054646\tValidation-f1_score:0.485944\n",
            "Stopping. Best iteration:\n",
            "[101]\tValidation-error:0.055272\tValidation-f1_score:0.494094\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weA6U5NwMTl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Reformatting test set for XGB ###\n",
        "dtest = xgb.DMatrix(test)\n",
        "\n",
        "### Predicting ###\n",
        "predict = xgb_model.predict(dtest) # predicting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KphWGzcJTfw",
        "colab_type": "text"
      },
      "source": [
        "# Generate Language With Flair Transfer Learning\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ZlS5qFJRKx",
        "colab_type": "code",
        "outputId": "c3128142-b34a-457a-d4da-4c01b3f277d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "import torch\n",
        "from flair.models import LanguageModel\n",
        "\n",
        "dataset = xgb_model\n",
        "\n",
        "# load the language model\n",
        "model = LanguageModel.load_language_model(dataset)\n",
        "\n",
        "idx2item = model.dictionary.idx2item\n",
        "\n",
        "# initial hidden state\n",
        "hidden = model.init_hidden(1)\n",
        "input = torch.rand(1, 1).mul(len(idx2item)).long()\n",
        "\n",
        "# generate text character by character\n",
        "characters = []\n",
        "number_of_characters_to_generate = 2000\n",
        "for i in range(number_of_characters_to_generate):\n",
        "    prediction, rnn_output, hidden = model.forward(input, hidden)\n",
        "    word_weights = prediction.squeeze().data.div(1.0).exp().cpu()\n",
        "    word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "    input.data.fill_(word_idx)\n",
        "    word = idx2item[word_idx].decode('UTF-8')\n",
        "    characters.append(word)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print('| Generated {}/{} chars'.format(i, number_of_characters_to_generate))\n",
        "\n",
        "# print generated text\n",
        "print(''.join(characters))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a13df63f75fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load the language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0midx2item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mload_language_model\u001b[0;34m(cls, model_file)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         model = LanguageModel(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '<xgboost.core.Booster object at 0x7f025032d3c8>'"
          ]
        }
      ]
    }
  ]
}